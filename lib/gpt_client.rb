# frozen_string_literal: true

class GptClient
  SUMMARY_PROMPT = <<~PROMPT
    ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº "ÐŸÐµÑ€ÐµÐºÐ°Ð· Ð±ÐµÑÑ–Ð´Ð¸ Ð·Ð° ÑÑŒÐ¾Ð³Ð¾Ð´Ð½Ñ–".
    ÐÐ°Ð¿Ð¸ÑˆÐ¸ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ð¿ÐµÑ€ÐµÐºÐ°Ð· Ð±ÐµÑÑ–Ð´Ð¸ Ð·Ð° ÑÑŒÐ¾Ð³Ð¾Ð´Ð½Ñ–. Ð Ð¾Ð±Ð¸ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÑ– Ð²Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸ Ð¿Ð¾ ÐºÐ¾Ð¶Ð½Ð¾Ð¼Ñƒ ÑƒÑ‡Ð°ÑÐ½Ð¸ÐºÑƒ Ð±ÐµÑÑ–Ð´Ð¸.
    Ð¡Ñ‚Ð¸Ð»ÑŒ Ð¿ÐµÑ€ÐµÐºÐ°Ð·Ñƒ: Ð½ÐµÑ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹.
    Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð²Ñ–Ñ…Ð´Ð½Ð¸Ñ… Ð´Ð°Ð½Ð¸Ñ…: "Ð†Ð¼'Ñ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°: Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ".
    Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð²Ð¸Ð²Ð¾Ð´Ñƒ: HTML Ð±ÐµÐ· Ñ‚ÐµÐ³Ñ–Ð² html, body, br, blockquote. Ð—Ð°Ð¼Ñ–Ð½Ð¸ Ñ‚ÐµÐ³Ð¸ h1, h2, h3 Ð½Ð° b, i, u Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ð¾. Ð”Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ñ– Ñ‚ÐµÐ³Ð¸: b, i, u, a, code, pre.
    Ð¯ÐºÑ‰Ð¾ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð¿ÑƒÑÑ‚Ñ–, Ð½Ð°Ð¿Ð¸ÑˆÐ¸ "ðŸ˜¥ Ð£ Ð¼ÐµÐ½Ðµ Ð½ÐµÐ¼Ð°Ñ” Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ— Ð·Ð° ÑÐµÐ³Ð¾Ð´Ð½Ñ".
  PROMPT

  CONTEXT_PROMPT = <<~PROMPT
    Ð”Ð°Ð»Ñ– Ð±ÑƒÐ´Ðµ Ð½Ð°Ð²ÐµÐ´ÐµÐ½Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð±ÐµÑÑ–Ð´Ð¸ Ð·Ð° ÑÑŒÐ¾Ð³Ð¾Ð´Ð½Ñ–
    Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð²Ñ–Ñ…Ð´Ð½Ð¸Ñ… Ð´Ð°Ð½Ð¸Ñ…: "Ð†Ð¼'Ñ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°: Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ".
    Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð²Ð¸Ð²Ð¾Ð´Ñƒ: HTML Ð±ÐµÐ· Ñ‚ÐµÐ³Ñ–Ð² html, body, br, blockquote. Ð—Ð°Ð¼Ñ–Ð½Ð¸ Ñ‚ÐµÐ³Ð¸ h1, h2, h3 Ð½Ð° b, i, u Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ð¾. Ð”Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ñ– Ñ‚ÐµÐ³Ð¸: b, i, u, a, code, pre.
    Ð¯ÐºÑ‰Ð¾ Ð´Ð°Ð»Ñ– Ð½Ðµ Ð±ÑƒÐ´Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¾Ð³Ð¾ Ñ€Ð°Ð½Ñ–ÑˆÐµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ, Ð´Ð°Ð¹ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð±ÐµÐ· ÑƒÑ€Ð°Ñ…ÑƒÐ²Ð°Ð½Ð½Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ.
  PROMPT

  attr_reader :client

  def initialize
    @client = OpenAI::Client.new
  end

  def get_summary_response(text)
    response = client.chat(parameters: {
                             model: 'gpt-4o-mini',
                             messages: [
                               { role: 'user', content: SUMMARY_PROMPT },
                               { role: 'user', content: text }
                             ]
                           })

    response.dig('choices', 0, 'message', 'content')
  end

  def get_prompt_response(context, prompt)
    response = client.chat(parameters: {
                             model: 'gpt-4o-mini',
                             messages: [
                               { role: 'user', content: CONTEXT_PROMPT },
                               { role: 'user', content: context },
                               { role: 'user', content: prompt }
                             ]
                           })

    response.dig('choices', 0, 'message', 'content')
  end
end
